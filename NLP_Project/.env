# Azure Subscription Variables
SUBSCRIPTION_ID = 'faee80d0-5c29-436f-971c-1c1afb1ce55d'
LOCATION = 'eastus2'
TENANT_ID = '3525e875-f76b-49bb-afa3-bb0e852fa269'
BASE_NAME = 'Nlp'
SP_APP_ID = '1083d742-11fb-4d0c-8911-615cf595ca7f'
SP_APP_SECRET = 'gau8Q~zp2rzamXm~R0uwSfIUwQQA3WdLOIs4Mcsk'
RESOURCE_GROUP = 'MLOps'

# Mock build/release ID for local testing
BUILD_ID = '001'

# Azure ML Workspace Variables
WORKSPACE_NAME = 'project_mlops'
EXPERIMENT_NAME = 'mlopspython'

# AML Compute Cluster Config
AML_ENV_NAME='NLP_sentiment_classification'
AML_ENV_TRAIN_CONDA_DEP_FILE="conda_dependencies.yml"
AML_COMPUTE_CLUSTER_NAME = 'train-cluster'
AML_COMPUTE_CLUSTER_CPU_SKU = 'STANDARD_DS2_V2'
AML_CLUSTER_MAX_NODES = '4'
AML_CLUSTER_MIN_NODES = '0'
AML_CLUSTER_PRIORITY = 'lowpriority'
# Training Config
MODEL_NAME = 'sentiment_classification.pkl'
MODEL_VERSION = '1'
TRAIN_SCRIPT_PATH = 'Training/model_training.py'


# AML Pipeline Config
TRAINING_PIPELINE_NAME = 'Training Pipeline'
MODEL_PATH = ''
EVALUATE_SCRIPT_PATH = 'Evaluation/model_evaluation.py'
REGISTER_SCRIPT_PATH = 'Registering/model_register.py'
SOURCES_DIR_TRAIN = 'Sentiment_Classification'
DATASET_NAME = 'News'
DATASET_VERSION = 'latest'
# Optional. Set it if you have configured non default datastore to point to your data
DATASTORE_NAME = ''
SCORE_SCRIPT = 'scoring/score.py'

# Optional. Used by a training pipeline with R on Databricks
DB_CLUSTER_ID = ''

# Optional. Container Image name for image creation
IMAGE_NAME = 'mltrained'

# Run Evaluation Step in AML pipeline
RUN_EVALUATION = 'true'

# Set to true cancels the Azure ML pipeline run when evaluation criteria are not met.
ALLOW_RUN_CANCEL = 'true'

# Flag to allow rebuilding the AML Environment after it was built for the first time. This enables dependency updates from conda_dependencies.yaml.
AML_REBUILD_ENVIRONMENT = 'false'



USE_GPU_FOR_SCORING = "false"
AML_ENV_SCORE_CONDA_DEP_FILE="conda_dependencies_scoring.yml"
AML_ENV_SCORECOPY_CONDA_DEP_FILE="conda_dependencies_scorecopy.yml"
# AML Compute Cluster Config for parallel batch scoring
AML_ENV_NAME_SCORING='diabetes_regression_scoring_env'
AML_ENV_NAME_SCORE_COPY='diabetes_regression_score_copy_env'
AML_COMPUTE_CLUSTER_NAME_SCORING = 'score-cluster'
AML_COMPUTE_CLUSTER_CPU_SKU_SCORING = 'STANDARD_DS2_V2'
AML_CLUSTER_MAX_NODES_SCORING = '4'
AML_CLUSTER_MIN_NODES_SCORING = '0'
AML_CLUSTER_PRIORITY_SCORING = 'lowpriority'
AML_REBUILD_ENVIRONMENT_SCORING = 'true'
BATCHSCORE_SCRIPT_PATH = 'scoring/parallel_batchscore.py'
BATCHSCORE_COPY_SCRIPT_PATH = 'scoring/parallel_batchscore_copyoutput.py'


SCORING_DATASTORE_INPUT_CONTAINER = 'input'
SCORING_DATASTORE_INPUT_FILENAME = 'diabetes_scoring_input.csv'
SCORING_DATASTORE_OUTPUT_CONTAINER = 'output'
SCORING_DATASTORE_OUTPUT_FILENAME = 'diabetes_scoring_output.csv'
SCORING_DATASET_NAME = 'diabetes_scoring_ds'
SCORING_PIPELINE_NAME = 'diabetes-scoring-pipeline'
